{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: xgboost in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement talib (from versions: none)\n",
      "ERROR: No matching distribution found for talib\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy xgboost scikit-learn jupyter talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TA-Lib in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from TA-Lib) (80.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from TA-Lib) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import talib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import talib\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BitcoinStrategy:\n",
    "    def __init__(self, fee_rate=0.001):\n",
    "        self.fee_rate = fee_rate\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def add_technical_indicators(self, df):    \n",
    "        \"\"\"Add technical indicators to the DataFrame.\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Ensure we have OHLCV columns\n",
    "        high = df['High'].values\n",
    "        low = df['Low'].values\n",
    "        close = df['Close'].values\n",
    "        volume = df['Volume'].values\n",
    "        \n",
    "        # Moving Averages\n",
    "        df['sma_20'] = talib.SMA(close, timeperiod=20)\n",
    "        df['sma_50'] = talib.SMA(close, timeperiod=50)\n",
    "        df['ema_20'] = talib.EMA(close, timeperiod=20)\n",
    "        \n",
    "        # MACD\n",
    "        df['macd'], df['macd_signal'], _ = talib.MACD(close)\n",
    "        \n",
    "        # RSI\n",
    "        df['rsi'] = talib.RSI(close, timeperiod=14)\n",
    "        \n",
    "        # Bollinger Bands\n",
    "        df['bb_upper'], df['bb_middle'], df['bb_lower'] = talib.BBANDS(close)\n",
    "        \n",
    "        # ATR\n",
    "        df['atr'] = talib.ATR(high, low, close, timeperiod=14)\n",
    "        \n",
    "        # Price Action Features\n",
    "        df['daily_return'] = df['Close'].pct_change()  # Use pct_change() directly on the DataFrame\n",
    "        df['high_low_range'] = df['High'] - df['Low']  # Calculate high-low range\n",
    "        df['close_open_range'] = df['Close'] - df['Open']  # Calculate close-open range\n",
    "        \n",
    "        # Clean up NaN values\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_features_targets(self, df):\n",
    "        \"\"\"Prepare features and targets for modeling.\"\"\"\n",
    "        df = df.copy()\n",
    "        df['Open time'] = pd.to_datetime(df['Open time'])\n",
    "        df.set_index('Open time', inplace=True)\n",
    "        \n",
    "        # Drop unnecessary columns\n",
    "        df.drop(columns=['Close time', 'Ignore'], inplace=True, errors='ignore')\n",
    "        \n",
    "        # Add technical indicators\n",
    "        df = self.add_technical_indicators(df)\n",
    "        \n",
    "        # Create target returns\n",
    "        df['target_return'] = df['Close'].pct_change(-1)\n",
    "        \n",
    "        # Clean data\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # Ensure all columns are numeric\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def select_features(self, df):\n",
    "        \"\"\"Select features for the model.\"\"\"\n",
    "        exclude_cols = ['Close', 'Volume', 'target_return']\n",
    "        features = [col for col in df.columns if col not in exclude_cols]\n",
    "        return features\n",
    "    \n",
    "    def rolling_predict(self, df, horizon=1, window_size=300):\n",
    "        \"\"\"Perform rolling predictions.\"\"\"\n",
    "        predictions = []\n",
    "        target_col = 'target_return'\n",
    "        \n",
    "        # Select features\n",
    "        features = self.select_features(df)\n",
    "        \n",
    "        # Initialize model\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        for i in range(window_size, len(df) - horizon):\n",
    "            # Get training data\n",
    "            train_df = df.iloc[i - window_size:i]\n",
    "            test_row = df.iloc[i]\n",
    "            \n",
    "            X_train = train_df[features]\n",
    "            y_train = train_df[target_col]\n",
    "            \n",
    "            # Remove NaN values\n",
    "            valid_idx = ~(X_train.isna().any(axis=1) | y_train.isna())\n",
    "            X_train = X_train[valid_idx]\n",
    "            y_train = y_train[valid_idx]\n",
    "            \n",
    "            if len(X_train) < 50:  # Minimum requirement\n",
    "                continue\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make prediction\n",
    "            X_test = test_row[features].values.reshape(1, -1)\n",
    "            if np.any(np.isnan(X_test)):\n",
    "                continue\n",
    "                \n",
    "            predicted_return = model.predict(X_test)[0]\n",
    "            predicted_return = np.clip(predicted_return, -0.15, 0.15)  # Clipping\n",
    "            \n",
    "            # Get actual return\n",
    "            actual_return = df.iloc[i + horizon - 1][target_col]\n",
    "            \n",
    "            # Calculate net return\n",
    "            signal = np.sign(predicted_return)\n",
    "            gross_return = signal * actual_return\n",
    "            net_return = gross_return - self.fee_rate\n",
    "            \n",
    "            predictions.append({\n",
    "                'date': df.index[i],\n",
    "                'predicted_return': predicted_return,\n",
    "                'actual_return': actual_return,\n",
    "                'net_return': net_return,\n",
    "                'signal': signal\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(predictions)\n",
    "    \n",
    "    def compute_metrics(self, results_df):\n",
    "        \"\"\"Calculate performance metrics.\"\"\"\n",
    "        if len(results_df) == 0:\n",
    "            return {\"Error\": \"No predictions generated\"}\n",
    "        \n",
    "        # Calculate cumulative returns\n",
    "        results_df['cumulative_return'] = (1 + results_df['net_return']).cumprod()\n",
    "        total_return = results_df['cumulative_return'].iloc[-1] - 1\n",
    "        \n",
    "        # Time-based metrics\n",
    "        days = (results_df['date'].iloc[-1] - results_df['date'].iloc[0]).days\n",
    "        annual_return = (1 + total_return) ** (365 / days) - 1\n",
    "        \n",
    "        # Risk metrics\n",
    "        daily_returns = results_df['net_return']\n",
    "        volatility = daily_returns.std() * np.sqrt(365)\n",
    "        sharpe_ratio = (annual_return - 0.02) / volatility if volatility > 0 else 0\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative = results_df['cumulative_return']\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_max) / running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Trading statistics\n",
    "        win_rate = (daily_returns > 0).sum() / len(daily_returns)\n",
    "        num_trades = (results_df['signal'] != 0).sum()\n",
    "        \n",
    "        return {\n",
    "            \"Total Return\": f\"{total_return*100:.2f}%\",\n",
    "            \"Annualized Return\": f\"{annual_return*100:.2f}%\",\n",
    "            \"Volatility (Annual)\": f\"{volatility*100:.2f}%\",\n",
    "            \"Sharpe Ratio\": round(sharpe_ratio, 3),\n",
    "            \"Max Drawdown\": f\"{max_drawdown*100:.2f}%\",\n",
    "            \"Win Rate\": f\"{win_rate*100:.2f}%\",\n",
    "            \"Total Trades\": int(num_trades)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_robust_strategy(df_path):\n",
    "    \"\"\"Run the robust strategy.\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    # Initialize strategy\n",
    "    strategy = BitcoinStrategy(fee_rate=0.001)\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"Preparing features and technical indicators...\")\n",
    "    df = strategy.prepare_features_targets(df)\n",
    "    print(f\"Data shape after feature engineering: {df.shape}\")\n",
    "    \n",
    "    # Test different horizons\n",
    "    horizons = [1, 7, 30, 180, 365]\n",
    "    results = {}\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        print(f\"\\n=== Testing {horizon}-day horizon ===\")\n",
    "        try:\n",
    "            predictions = strategy.rolling_predict(df, horizon=horizon)\n",
    "            metrics = strategy.compute_metrics(predictions)\n",
    "            results[f\"{horizon}_day\"] = {\n",
    "                'metrics': metrics,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "            \n",
    "            print(f\"Results for {horizon}-day strategy:\")\n",
    "            for key, value in metrics.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {horizon}-day horizon: {e}\")\n",
    "            results[f\"{horizon}_day\"] = {\"Error\": str(e)}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features and technical indicators...\n",
      "Data shape after feature engineering: (2655, 23)\n",
      "\n",
      "=== Testing 1-day horizon ===\n",
      "Results for 1-day strategy:\n",
      "  Total Return: -99.93%\n",
      "  Annualized Return: -67.59%\n",
      "  Volatility (Annual): 67.90%\n",
      "  Sharpe Ratio: -1.025\n",
      "  Max Drawdown: -99.95%\n",
      "  Win Rate: 46.52%\n",
      "  Total Trades: 2354\n",
      "\n",
      "=== Testing 7-day horizon ===\n",
      "Results for 7-day strategy:\n",
      "  Total Return: 231.60%\n",
      "  Annualized Return: 20.49%\n",
      "  Volatility (Annual): 67.68%\n",
      "  Sharpe Ratio: 0.273\n",
      "  Max Drawdown: -63.58%\n",
      "  Win Rate: 49.96%\n",
      "  Total Trades: 2348\n",
      "\n",
      "=== Testing 30-day horizon ===\n",
      "Results for 30-day strategy:\n",
      "  Total Return: -99.07%\n",
      "  Annualized Return: -52.03%\n",
      "  Volatility (Annual): 67.72%\n",
      "  Sharpe Ratio: -0.798\n",
      "  Max Drawdown: -99.29%\n",
      "  Win Rate: 47.66%\n",
      "  Total Trades: 2325\n",
      "\n",
      "=== Testing 180-day horizon ===\n",
      "Results for 180-day strategy:\n",
      "  Total Return: -92.08%\n",
      "  Annualized Return: -34.67%\n",
      "  Volatility (Annual): 68.37%\n",
      "  Sharpe Ratio: -0.536\n",
      "  Max Drawdown: -92.29%\n",
      "  Win Rate: 48.41%\n",
      "  Total Trades: 2175\n",
      "\n",
      "=== Testing 365-day horizon ===\n",
      "Results for 365-day strategy:\n",
      "  Total Return: -94.55%\n",
      "  Annualized Return: -41.36%\n",
      "  Volatility (Annual): 67.62%\n",
      "  Sharpe Ratio: -0.641\n",
      "  Max Drawdown: -96.28%\n",
      "  Win Rate: 47.99%\n",
      "  Total Trades: 1990\n"
     ]
    }
   ],
   "source": [
    "results = run_robust_strategy('btc_1d_data_2018_to_2025.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
