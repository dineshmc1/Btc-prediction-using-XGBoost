{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: xgboost in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (C:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (C:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement talib (from versions: none)\n",
      "ERROR: No matching distribution found for talib\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy xgboost scikit-learn jupyter talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: TA-Lib in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.6.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from TA-Lib) (80.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rdine\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from TA-Lib) (1.26.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~treamlit (c:\\Users\\rdine\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import talib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedBitcoinStrategy:\n",
    "    def __init__(self, fee_rate=0.001):\n",
    "        self.fee_rate = fee_rate\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def add_technical_indicators(self, df):\n",
    "        \"\"\"Add comprehensive technical indicators\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # Ensure we have OHLCV columns\n",
    "        high = df['High'].values\n",
    "        low = df['Low'].values\n",
    "        close = df['Close'].values\n",
    "        volume = df['Volume'].values\n",
    "        open_price = df['Open'].values\n",
    "        \n",
    "        # === TREND INDICATORS ===\n",
    "        # Moving Averages\n",
    "        df['sma_5'] = talib.SMA(close, timeperiod=5)\n",
    "        df['sma_10'] = talib.SMA(close, timeperiod=10)\n",
    "        df['sma_20'] = talib.SMA(close, timeperiod=20)\n",
    "        df['sma_50'] = talib.SMA(close, timeperiod=50)\n",
    "        df['sma_100'] = talib.SMA(close, timeperiod=100)\n",
    "        \n",
    "        df['ema_5'] = talib.EMA(close, timeperiod=5)\n",
    "        df['ema_10'] = talib.EMA(close, timeperiod=10)\n",
    "        df['ema_20'] = talib.EMA(close, timeperiod=20)\n",
    "        df['ema_50'] = talib.EMA(close, timeperiod=50)\n",
    "        \n",
    "        # MACD\n",
    "        df['macd'], df['macd_signal'], df['macd_hist'] = talib.MACD(close)\n",
    "        \n",
    "        # ADX (Trend Strength)\n",
    "        df['adx'] = talib.ADX(high, low, close, timeperiod=14)\n",
    "        df['plus_di'] = talib.PLUS_DI(high, low, close, timeperiod=14)\n",
    "        df['minus_di'] = talib.MINUS_DI(high, low, close, timeperiod=14)\n",
    "        \n",
    "        # === MOMENTUM INDICATORS ===\n",
    "        # RSI\n",
    "        df['rsi_14'] = talib.RSI(close, timeperiod=14)\n",
    "        df['rsi_21'] = talib.RSI(close, timeperiod=21)\n",
    "        \n",
    "        # Stochastic\n",
    "        df['stoch_k'], df['stoch_d'] = talib.STOCH(high, low, close)\n",
    "        \n",
    "        # Williams %R\n",
    "        df['williams_r'] = talib.WILLR(high, low, close, timeperiod=14)\n",
    "        \n",
    "        # CCI\n",
    "        df['cci'] = talib.CCI(high, low, close, timeperiod=14)\n",
    "        \n",
    "        # ROC (Rate of Change)\n",
    "        df['roc_5'] = talib.ROC(close, timeperiod=5)\n",
    "        df['roc_10'] = talib.ROC(close, timeperiod=10)\n",
    "        df['roc_20'] = talib.ROC(close, timeperiod=20)\n",
    "        \n",
    "        # === VOLATILITY INDICATORS ===\n",
    "        # Bollinger Bands\n",
    "        df['bb_upper'], df['bb_middle'], df['bb_lower'] = talib.BBANDS(close)\n",
    "        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / df['bb_middle']\n",
    "        df['bb_position'] = (close - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])\n",
    "        \n",
    "        # ATR (Average True Range)\n",
    "        df['atr'] = talib.ATR(high, low, close, timeperiod=14)\n",
    "        \n",
    "        # === VOLUME INDICATORS ===\n",
    "        # Volume SMA\n",
    "        df['volume_sma_10'] = talib.SMA(volume, timeperiod=10)\n",
    "        df['volume_sma_20'] = talib.SMA(volume, timeperiod=20)\n",
    "        \n",
    "        # On Balance Volume\n",
    "        df['obv'] = talib.OBV(close, volume)\n",
    "        \n",
    "        # Volume Rate of Change\n",
    "        df['volume_roc'] = talib.ROC(volume, timeperiod=10)\n",
    "        \n",
    "        # === PRICE PATTERNS ===\n",
    "        # Price ratios\n",
    "        df['price_sma20_ratio'] = close / df['sma_20']\n",
    "        df['price_sma50_ratio'] = close / df['sma_50']\n",
    "        df['sma20_sma50_ratio'] = df['sma_20'] / df['sma_50']\n",
    "        df['ema10_ema20_ratio'] = df['ema_10'] / df['ema_20']\n",
    "        \n",
    "        # High-Low ratios\n",
    "        df['hl_ratio'] = high / low\n",
    "        df['close_high_ratio'] = close / high\n",
    "        df['close_low_ratio'] = close / low\n",
    "        \n",
    "        # === CUSTOM INDICATORS ===\n",
    "        # Volatility\n",
    "        df['volatility_5'] = df['Close'].rolling(5).std()\n",
    "        df['volatility_10'] = df['Close'].rolling(10).std()\n",
    "        df['volatility_20'] = df['Close'].rolling(20).std()\n",
    "        \n",
    "        # Price momentum\n",
    "        df['momentum_5'] = close / df['Close'].shift(5) - 1\n",
    "        df['momentum_10'] = close / df['Close'].shift(10) - 1\n",
    "        df['momentum_20'] = close / df['Close'].shift(20) - 1\n",
    "        \n",
    "        # Volume momentum\n",
    "        df['volume_momentum'] = volume / df['volume_sma_10']\n",
    "        \n",
    "        # === LAG FEATURES ===\n",
    "        # Lag important indicators\n",
    "        for lag in [1, 2, 3, 5, 7]:\n",
    "            df[f'rsi_lag_{lag}'] = df['rsi_14'].shift(lag)\n",
    "            df[f'macd_lag_{lag}'] = df['macd'].shift(lag)\n",
    "            df[f'momentum_lag_{lag}'] = df['momentum_5'].shift(lag)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def prepare_features_targets(self, df):\n",
    "        \"\"\"Prepare features and targets\"\"\"\n",
    "        df = df.copy()\n",
    "        df['Open time'] = pd.to_datetime(df['Open time'])\n",
    "        df = df.sort_values('Open time')\n",
    "        df.set_index('Open time', inplace=True)\n",
    "        \n",
    "        # Drop unnecessary columns\n",
    "        df.drop(columns=['Close time', 'Ignore'], inplace=True, errors='ignore')\n",
    "        \n",
    "        # Add technical indicators\n",
    "        df = self.add_technical_indicators(df)\n",
    "        \n",
    "        # Create target returns\n",
    "        df['target_return_1'] = df['Close'].pct_change(-1)\n",
    "        df['target_return_3'] = (df['Close'].shift(-3) / df['Close']) - 1\n",
    "        df['target_return_5'] = (df['Close'].shift(-5) / df['Close']) - 1\n",
    "        df['target_return_7'] = (df['Close'].shift(-7) / df['Close']) - 1\n",
    "        df['target_return_14'] = (df['Close'].shift(-14) / df['Close']) - 1\n",
    "        \n",
    "        # Clean data\n",
    "        df = df.replace([np.inf, -np.inf], np.nan)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Cap extreme values\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_cols:\n",
    "            if 'return' in col or 'roc' in col or 'momentum' in col:\n",
    "                df[col] = df[col].clip(-1, 1)  # Cap at ±100%\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def select_features(self, df):\n",
    "        \"\"\"Select the most important features\"\"\"\n",
    "        # Exclude target columns and raw OHLCV\n",
    "        exclude_cols = [\n",
    "            'Open', 'High', 'Low', 'Close', 'Volume', \n",
    "            'Number of trades', 'Taker buy base asset volume', \n",
    "            'Taker buy quote asset volume'\n",
    "        ] + [col for col in df.columns if col.startswith('target_')]\n",
    "        \n",
    "        features = [col for col in df.columns if col not in exclude_cols]\n",
    "        \n",
    "        # Prioritize most important technical indicators\n",
    "        priority_features = [\n",
    "            'rsi_14', 'macd', 'macd_signal', 'bb_position', 'bb_width',\n",
    "            'adx', 'atr', 'cci', 'williams_r', 'stoch_k', 'stoch_d',\n",
    "            'price_sma20_ratio', 'price_sma50_ratio', 'sma20_sma50_ratio',\n",
    "            'ema10_ema20_ratio', 'momentum_5', 'momentum_10', 'volatility_10',\n",
    "            'volume_momentum', 'obv', 'plus_di', 'minus_di'\n",
    "        ]\n",
    "        \n",
    "        # Add lag features\n",
    "        lag_features = [col for col in features if 'lag_' in col]\n",
    "        \n",
    "        # Combine priority and lag features\n",
    "        selected_features = []\n",
    "        for feat in priority_features + lag_features:\n",
    "            if feat in features:\n",
    "                selected_features.append(feat)\n",
    "        \n",
    "        # Add remaining features up to a limit\n",
    "        remaining_features = [f for f in features if f not in selected_features]\n",
    "        selected_features.extend(remaining_features[:20])  # Limit total features\n",
    "        \n",
    "        return selected_features\n",
    "    \n",
    "    def generate_signals(self, predictions, current_indicators):\n",
    "        \"\"\"Advanced signal generation with multiple filters\"\"\"\n",
    "        signals = []\n",
    "        \n",
    "        for i, pred in enumerate(predictions):\n",
    "            # Get current market conditions\n",
    "            rsi = current_indicators.get('rsi_14', 50)\n",
    "            bb_pos = current_indicators.get('bb_position', 0.5)\n",
    "            adx = current_indicators.get('adx', 25)\n",
    "            macd = current_indicators.get('macd', 0)\n",
    "            macd_signal = current_indicators.get('macd_signal', 0)\n",
    "            volatility = current_indicators.get('volatility_10', 0.02)\n",
    "            \n",
    "            # Signal strength based on prediction\n",
    "            signal_strength = abs(pred)\n",
    "            \n",
    "            # Market condition filters\n",
    "            trend_filter = True\n",
    "            momentum_filter = True\n",
    "            volatility_filter = True\n",
    "            \n",
    "            # 1. Trend Filter (ADX > 25 for trending markets)\n",
    "            if adx < 20:\n",
    "                trend_filter = False\n",
    "            \n",
    "            # 2. Momentum Filter (RSI not in extreme zones)\n",
    "            if rsi > 80 and pred > 0:  # Don't buy when overbought\n",
    "                momentum_filter = False\n",
    "            elif rsi < 20 and pred < 0:  # Don't sell when oversold\n",
    "                momentum_filter = False\n",
    "            \n",
    "            # 3. MACD Confirmation\n",
    "            if pred > 0 and macd < macd_signal:  # Don't buy if MACD bearish\n",
    "                momentum_filter = False\n",
    "            elif pred < 0 and macd > macd_signal:  # Don't sell if MACD bullish\n",
    "                momentum_filter = False\n",
    "            \n",
    "            # 4. Volatility Filter (avoid trading in extreme volatility)\n",
    "            if volatility > 0.1:  # More than 10% daily volatility\n",
    "                volatility_filter = False\n",
    "            \n",
    "            # 5. Bollinger Band Filter\n",
    "            if bb_pos > 0.8 and pred > 0:  # Don't buy near upper band\n",
    "                momentum_filter = False\n",
    "            elif bb_pos < 0.2 and pred < 0:  # Don't sell near lower band\n",
    "                momentum_filter = False\n",
    "            \n",
    "            # Generate final signal\n",
    "            if (signal_strength > 0.02 and  # Minimum 2% predicted return\n",
    "                trend_filter and momentum_filter and volatility_filter):\n",
    "                signal = np.sign(pred)\n",
    "            else:\n",
    "                signal = 0  # No trade\n",
    "            \n",
    "            signals.append(signal)\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def rolling_predict(self, df, horizon=5, window_size=500):\n",
    "        \"\"\"Advanced rolling prediction with ensemble models\"\"\"\n",
    "        predictions = []\n",
    "        target_col = f'target_return_{horizon}'\n",
    "        \n",
    "        # Select features\n",
    "        features = self.select_features(df)\n",
    "        print(f\"Using {len(features)} features for prediction\")\n",
    "        \n",
    "        # Create ensemble of models\n",
    "        models = [\n",
    "            XGBRegressor(\n",
    "                n_estimators=100, max_depth=4, learning_rate=0.1,\n",
    "                subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
    "                reg_alpha=0.1, reg_lambda=0.1\n",
    "            ),\n",
    "            XGBRegressor(\n",
    "                n_estimators=150, max_depth=3, learning_rate=0.05,\n",
    "                subsample=0.9, colsample_bytree=0.9, random_state=123,\n",
    "                reg_alpha=0.05, reg_lambda=0.05\n",
    "            ),\n",
    "            RandomForestRegressor(\n",
    "                n_estimators=100, max_depth=5, random_state=42,\n",
    "                min_samples_split=10, min_samples_leaf=5\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        for i in range(window_size, len(df) - horizon):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processing sample {i}/{len(df) - horizon}\")\n",
    "            \n",
    "            # Get training data\n",
    "            train_df = df.iloc[i - window_size:i]\n",
    "            test_row = df.iloc[i]\n",
    "            \n",
    "            X_train = train_df[features]\n",
    "            y_train = train_df[target_col]\n",
    "            \n",
    "            # Remove NaN values\n",
    "            valid_idx = ~(X_train.isna().any(axis=1) | y_train.isna())\n",
    "            X_train = X_train[valid_idx]\n",
    "            y_train = y_train[valid_idx]\n",
    "            \n",
    "            if len(X_train) < 100:\n",
    "                continue\n",
    "            \n",
    "            # Scale features\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(test_row[features].values.reshape(1, -1))\n",
    "            \n",
    "            # Ensemble prediction\n",
    "            ensemble_predictions = []\n",
    "            for model in models:\n",
    "                if hasattr(model, 'tree_method'):  # XGBoost\n",
    "                    model.fit(X_train, y_train)\n",
    "                    pred = model.predict(test_row[features].values.reshape(1, -1))[0]\n",
    "                else:  # RandomForest\n",
    "                    model.fit(X_train_scaled, y_train)\n",
    "                    pred = model.predict(X_test_scaled)[0]\n",
    "                \n",
    "                ensemble_predictions.append(pred)\n",
    "            \n",
    "            # Average ensemble prediction\n",
    "            predicted_return = np.mean(ensemble_predictions)\n",
    "            predicted_return = np.clip(predicted_return, -0.2, 0.2)  # Cap at ±20%\n",
    "            \n",
    "            # Get actual return\n",
    "            actual_return = df.iloc[i + horizon - 1][target_col]\n",
    "            \n",
    "            # Get current indicators for signal generation\n",
    "            current_indicators = test_row[features].to_dict()\n",
    "            \n",
    "            # Generate signal using advanced logic\n",
    "            signal = self.generate_signals([predicted_return], current_indicators)[0]\n",
    "            \n",
    "            # Calculate returns\n",
    "            if signal != 0:\n",
    "                gross_return = signal * actual_return\n",
    "                # Position-based fee calculation\n",
    "                net_return = gross_return - self.fee_rate\n",
    "            else:\n",
    "                net_return = 0\n",
    "            \n",
    "            predictions.append({\n",
    "                'date': df.index[i],\n",
    "                'predicted_return': predicted_return,\n",
    "                'actual_return': actual_return,\n",
    "                'net_return': net_return,\n",
    "                'signal': signal,\n",
    "                'rsi': current_indicators.get('rsi_14', 50),\n",
    "                'macd': current_indicators.get('macd', 0),\n",
    "                'bb_position': current_indicators.get('bb_position', 0.5)\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(predictions)\n",
    "    \n",
    "    def compute_metrics(self, results_df):\n",
    "        \"\"\"Comprehensive metrics calculation\"\"\"\n",
    "        if len(results_df) == 0:\n",
    "            return {\"Error\": \"No predictions generated\"}\n",
    "        \n",
    "        # Calculate cumulative returns\n",
    "        results_df['cumulative_return'] = (1 + results_df['net_return']).cumprod()\n",
    "        total_return = results_df['cumulative_return'].iloc[-1] - 1\n",
    "        \n",
    "        # Time-based metrics\n",
    "        days = (results_df['date'].iloc[-1] - results_df['date'].iloc[0]).days\n",
    "        annual_return = (1 + total_return) ** (365 / days) - 1\n",
    "        \n",
    "        # Risk metrics\n",
    "        daily_returns = results_df['net_return']\n",
    "        volatility = daily_returns.std() * np.sqrt(365)\n",
    "        sharpe_ratio = (annual_return - 0.02) / volatility if volatility > 0 else 0  # Assume 2% risk-free rate\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative = results_df['cumulative_return']\n",
    "        running_max = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_max) / running_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        \n",
    "        # Trading statistics\n",
    "        win_rate = (daily_returns > 0).sum() / len(daily_returns)\n",
    "        num_trades = (results_df['signal'] != 0).sum()\n",
    "        \n",
    "        # Profit factor\n",
    "        winning_trades = daily_returns[daily_returns > 0].sum()\n",
    "        losing_trades = abs(daily_returns[daily_returns < 0].sum())\n",
    "        profit_factor = winning_trades / losing_trades if losing_trades > 0 else np.inf\n",
    "        \n",
    "        # Sortino ratio (downside deviation)\n",
    "        downside_returns = daily_returns[daily_returns < 0]\n",
    "        downside_std = downside_returns.std() * np.sqrt(365) if len(downside_returns) > 0 else 0\n",
    "        sortino_ratio = (annual_return - 0.02) / downside_std if downside_std > 0 else 0\n",
    "        \n",
    "        # Calmar ratio\n",
    "        calmar_ratio = annual_return / abs(max_drawdown) if max_drawdown < 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"Total Return\": f\"{total_return*100:.2f}%\",\n",
    "            \"Annualized Return\": f\"{annual_return*100:.2f}%\",\n",
    "            \"Volatility (Annual)\": f\"{volatility*100:.2f}%\",\n",
    "            \"Sharpe Ratio\": round(sharpe_ratio, 3),\n",
    "            \"Sortino Ratio\": round(sortino_ratio, 3),\n",
    "            \"Calmar Ratio\": round(calmar_ratio, 3),\n",
    "            \"Max Drawdown\": f\"{max_drawdown*100:.2f}%\",\n",
    "            \"Win Rate\": f\"{win_rate*100:.2f}%\",\n",
    "            \"Total Trades\": int(num_trades),\n",
    "            \"Trades per Month\": round(num_trades / (days/30), 1),\n",
    "            \"Profit Factor\": round(profit_factor, 2),\n",
    "            \"Best Day\": f\"{daily_returns.max()*100:.2f}%\",\n",
    "            \"Worst Day\": f\"{daily_returns.min()*100:.2f}%\",\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_advanced_strategy(df_path):\n",
    "    \"\"\"Run the advanced strategy\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(df_path)\n",
    "    \n",
    "    # Initialize strategy\n",
    "    strategy = AdvancedBitcoinStrategy(fee_rate=0.001)\n",
    "    \n",
    "    # Prepare data\n",
    "    print(\"Preparing features and technical indicators...\")\n",
    "    df = strategy.prepare_features_targets(df)\n",
    "    print(f\"Data shape after feature engineering: {df.shape}\")\n",
    "    \n",
    "    # Test different horizons\n",
    "    horizons = [3, 5, 7, 14]\n",
    "    results = {}\n",
    "    \n",
    "    for horizon in horizons:\n",
    "        print(f\"\\n=== Testing {horizon}-day horizon ===\")\n",
    "        try:\n",
    "            predictions = strategy.rolling_predict(df, horizon=horizon)\n",
    "            metrics = strategy.compute_metrics(predictions)\n",
    "            results[f\"{horizon}_day\"] = {\n",
    "                'metrics': metrics,\n",
    "                'predictions': predictions\n",
    "            }\n",
    "            \n",
    "            print(f\"Results for {horizon}-day strategy:\")\n",
    "            for key, value in metrics.items():\n",
    "                print(f\"  {key}: {value}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error with {horizon}-day horizon: {e}\")\n",
    "            results[f\"{horizon}_day\"] = {\"Error\": str(e)}\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing features and technical indicators...\n",
      "Data shape after feature engineering: (2592, 77)\n",
      "\n",
      "=== Testing 3-day horizon ===\n",
      "Using 57 features for prediction\n",
      "Processing sample 500/2589\n",
      "Processing sample 600/2589\n",
      "Processing sample 700/2589\n",
      "Processing sample 800/2589\n",
      "Processing sample 900/2589\n",
      "Processing sample 1000/2589\n",
      "Processing sample 1100/2589\n",
      "Processing sample 1200/2589\n"
     ]
    }
   ],
   "source": [
    "results = run_advanced_strategy(\"btc_1d_data_2018_to_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_strategy = None\n",
    "best_return = -999\n",
    "for strategy_name, result in results.items():\n",
    "    if 'metrics' in result:\n",
    "        total_return = float(result['metrics']['Total Return'].replace('%', ''))\n",
    "        if total_return > best_return:\n",
    "            best_return = total_return\n",
    "            best_strategy = strategy_name\n",
    "\n",
    "print(f\"\\nBest performing strategy: {best_strategy} with {best_return:.2f}% return\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
